{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from functools import lru_cache\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_ml.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_capitalized_words(_text):\n",
    "    regex_capital_letters = re.compile(\"([А-Я]{4,}|НЕ|ДА)\")\n",
    "    try:\n",
    "        _found = regex_capital_letters.findall(_text)\n",
    "        if len(_found) == 0:\n",
    "            return []\n",
    "        return _found\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def get_exclamations(_text):\n",
    "    regex_exclamation = re.compile(\"(\\!+|\\?+|\\.{3}|\\:\\(|\\:\\)|\\){2,}|\\({2,})\")\n",
    "    try:\n",
    "        _found = regex_exclamation.findall(_text)\n",
    "        if len(_found) == 0:\n",
    "            return []\n",
    "        return _found\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def words_only(_text):\n",
    "    regex = re.compile(\"[А-Яа-яA-z]+\")\n",
    "    try:\n",
    "        return regex.findall(_text.lower())\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=128)\n",
    "def lemmatize_word(_token):\n",
    "    pymorphy = MorphAnalyzer()\n",
    "    return pymorphy.parse(_token)[0].normal_form\n",
    "\n",
    "def lemmatize_text(_text):\n",
    "    return [lemmatize_word(w) for w in _text]\n",
    "\n",
    "def remove_stopwords(_lemmas):\n",
    "    with open(\"stopwords_filtered\", \"rb\") as _fp:\n",
    "        _stopwords = pickle.load(_fp)\n",
    "    return [w for w in _lemmas if not w in _stopwords and len(w) > 1]\n",
    "\n",
    "\n",
    "def clean_text(_text):\n",
    "    tokens = words_only(_text)\n",
    "    _lemmas = lemmatize_text(tokens)\n",
    "    return ' '.join(remove_stopwords(_lemmas))\n",
    "\n",
    "def add_lemmas():\n",
    "    with Pool(4) as p:\n",
    "        lemmas = list(tqdm(p.imap(clean_text, df['feeds']), total=len(df)))\n",
    "    df['lemmas'] = lemmas\n",
    "\n",
    "def merge_lemmas():\n",
    "    df['lemmas_full'] = df['lemmas'].apply(lambda x: x.split()) + df['capswords'] + df['exclamation']\n",
    "    df['lemmas_full'] = df['lemmas_full'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "def add_words_counter():\n",
    "    df['sym_len'] = df['feeds'].apply(len)\n",
    "    df['word_len'] = df['feeds'].apply(lambda x: len(x.split()))\n",
    "    df['caps_count'] = df['capswords'].apply(lambda x: len(x))\n",
    "    df['exclaim_count'] = df['exclamation'].apply(lambda x: len(x))\n",
    "\n",
    "def bank_freq():\n",
    "    bank_freq = df.groupby('bank').size() / len(df)\n",
    "    df.loc[:, 'bank_freq'] = df['bank'].map(bank_freq)\n",
    "\n",
    "def drop_columns():\n",
    "    df.drop(['date', 'exclamation', 'capswords', 'feeds', 'lemmas', 'bank'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df = df.dropna()\n",
    "df.astype({'grades': 'int32'})\n",
    "df['capswords'] = df.loc[:, 'feeds'].apply(get_capitalized_words)\n",
    "df['exclamation'] = df.loc[:, 'feeds'].apply(get_exclamations)\n",
    "\n",
    "# add_lemmas()\n",
    "# merge_lemmas()\n",
    "# add_words_counter()\n",
    "# df.to_csv('train_lemmas_new.csv')\n",
    "# drop_columns()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#with Pool(4) as p:\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#lemmas = list(tqdm(p.imap(clean_text, df['feeds']), total=len(df)))\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m lemmas \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfeeds\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclean_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m#df['lemmas'] = lemmas\u001B[39;00m\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pandas/core/series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[0;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[1;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[1;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[1;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[1;32m   4668\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[1;32m   4670\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[1;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m   1104\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[0;32m-> 1105\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pandas/core/apply.py:1156\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1154\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1155\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1156\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1157\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1158\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1159\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1160\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[1;32m   1163\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[1;32m   1164\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[1;32m   1165\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2918\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "Cell \u001B[0;32mIn[3], line 45\u001B[0m, in \u001B[0;36mclean_text\u001B[0;34m(_text)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mclean_text\u001B[39m(_text):\n\u001B[1;32m     44\u001B[0m     tokens \u001B[38;5;241m=\u001B[39m words_only(_text)\n\u001B[0;32m---> 45\u001B[0m     _lemmas \u001B[38;5;241m=\u001B[39m \u001B[43mlemmatize_text\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokens\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(remove_stopwords(_lemmas))\n",
      "Cell \u001B[0;32mIn[3], line 35\u001B[0m, in \u001B[0;36mlemmatize_text\u001B[0;34m(_text)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlemmatize_text\u001B[39m(_text):\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [lemmatize_word(w) \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m _text]\n",
      "Cell \u001B[0;32mIn[3], line 35\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlemmatize_text\u001B[39m(_text):\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mlemmatize_word\u001B[49m\u001B[43m(\u001B[49m\u001B[43mw\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m _text]\n",
      "Cell \u001B[0;32mIn[3], line 31\u001B[0m, in \u001B[0;36mlemmatize_word\u001B[0;34m(_token)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;129m@lru_cache\u001B[39m(maxsize\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlemmatize_word\u001B[39m(_token):\n\u001B[0;32m---> 31\u001B[0m     pymorphy \u001B[38;5;241m=\u001B[39m \u001B[43mMorphAnalyzer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m pymorphy\u001B[38;5;241m.\u001B[39mparse(_token)[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnormal_form\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pymorphy2/analyzer.py:203\u001B[0m, in \u001B[0;36mMorphAnalyzer.__init__\u001B[0;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001B[0m\n\u001B[1;32m    200\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoose_dictionary_path(path, lang)\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m--> 203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdictionary \u001B[38;5;241m=\u001B[39m \u001B[43mopencorpora_dict\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDictionary\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    204\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlang \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchoose_language(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdictionary, lang)\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprob_estimator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_prob_estimator(\n\u001B[1;32m    207\u001B[0m         probability_estimator_cls, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdictionary, path\n\u001B[1;32m    208\u001B[0m     )\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pymorphy2/opencorpora_dict/wrapper.py:18\u001B[0m, in \u001B[0;36mDictionary.__init__\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, path):\n\u001B[1;32m     16\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLoading dictionaries from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, path)\n\u001B[0;32m---> 18\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data \u001B[38;5;241m=\u001B[39m \u001B[43mload_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat: \u001B[39m\u001B[38;5;132;01m%(format_version)s\u001B[39;00m\u001B[38;5;124m, revision: \u001B[39m\u001B[38;5;132;01m%(source_revision)s\u001B[39;00m\u001B[38;5;124m, updated: \u001B[39m\u001B[38;5;132;01m%(compiled_at)s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data\u001B[38;5;241m.\u001B[39mmeta)\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;66;03m# attributes from opencorpora_dict.storage.LoadedDictionary\u001B[39;00m\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pymorphy2/opencorpora_dict/storage.py:55\u001B[0m, in \u001B[0;36mload_dict\u001B[0;34m(path, gramtab_format)\u001B[0m\n\u001B[1;32m     52\u001B[0m Tag \u001B[38;5;241m=\u001B[39m _load_tag_class(gramtab_format, _f(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrammemes.json\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     54\u001B[0m str_gramtab \u001B[38;5;241m=\u001B[39m _load_gramtab(meta, gramtab_format, path)\n\u001B[0;32m---> 55\u001B[0m gramtab \u001B[38;5;241m=\u001B[39m [Tag(tag_str) \u001B[38;5;28;01mfor\u001B[39;00m tag_str \u001B[38;5;129;01min\u001B[39;00m str_gramtab]\n\u001B[1;32m     57\u001B[0m suffixes \u001B[38;5;241m=\u001B[39m json_read(_f(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msuffixes.json\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     58\u001B[0m paradigms \u001B[38;5;241m=\u001B[39m _load_paradigms(_f(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparadigms.array\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pymorphy2/opencorpora_dict/storage.py:55\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     52\u001B[0m Tag \u001B[38;5;241m=\u001B[39m _load_tag_class(gramtab_format, _f(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrammemes.json\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     54\u001B[0m str_gramtab \u001B[38;5;241m=\u001B[39m _load_gramtab(meta, gramtab_format, path)\n\u001B[0;32m---> 55\u001B[0m gramtab \u001B[38;5;241m=\u001B[39m [\u001B[43mTag\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtag_str\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m tag_str \u001B[38;5;129;01min\u001B[39;00m str_gramtab]\n\u001B[1;32m     57\u001B[0m suffixes \u001B[38;5;241m=\u001B[39m json_read(_f(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msuffixes.json\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     58\u001B[0m paradigms \u001B[38;5;241m=\u001B[39m _load_paradigms(_f(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparadigms.array\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m~/work/projects/bootcamp_kaggle/venv/lib/python3.10/site-packages/pymorphy2/tagset.py:278\u001B[0m, in \u001B[0;36mOpencorporaTag.__init__\u001B[0;34m(self, tag)\u001B[0m\n\u001B[1;32m    275\u001B[0m grammemes \u001B[38;5;241m=\u001B[39m tag\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    276\u001B[0m grammemes_tuple \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m([intern(\u001B[38;5;28mstr\u001B[39m(g)) \u001B[38;5;28;01mfor\u001B[39;00m g \u001B[38;5;129;01min\u001B[39;00m grammemes])\n\u001B[0;32m--> 278\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_assert_grammemes_are_known(\u001B[38;5;28;43mset\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mgrammemes_tuple\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    280\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_grammemes_tuple \u001B[38;5;241m=\u001B[39m grammemes_tuple\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_POS \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_grammemes_tuple[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#with Pool(4) as p:\n",
    "#lemmas = list(tqdm(p.imap(clean_text, df['feeds']), total=len(df)))\n",
    "lemmas = df['feeds'].apply(clean_text)\n",
    "#df['lemmas'] = lemmas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "bow = vec.fit_transform(df['lemmas_full'])\n",
    "joblib.dump(vec, 'vectorizer_f_new.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = df.grades\n",
    "y_train = y_train.reset_index().drop(columns='index')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "selector = SelectKBest(chi2, k = 5000 )\n",
    "selector.fit(bow, y_train)\n",
    "X_train_sel = selector.transform(bow)\n",
    "joblib.dump(selector, 'selector_f_new.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
